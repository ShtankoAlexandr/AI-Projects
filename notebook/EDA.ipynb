{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c1c8cb",
   "metadata": {},
   "source": [
    "# Importing modules and setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Adding path to scripts so that modules from ../scripts can be imported\n",
    "sys.path.append(os.path.abspath('../scripts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77d575",
   "metadata": {},
   "source": [
    "## Importing functions from the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_feature_engineering import load_and_preprocess_data, split_and_scale\n",
    "from model_selection import (\n",
    "    train_models_with_gridsearch,\n",
    "    evaluate_models,\n",
    "    plot_confusion_matrix,\n",
    "    plot_learning_curve,\n",
    "    save_best_model,\n",
    "    update_readme\n",
    ")\n",
    "from predict import predict_and_save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8539151",
   "metadata": {},
   "source": [
    "## Load and initial analysis of data (train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the training file\n",
    "path_train = '../data/train.csv'\n",
    "\n",
    "# Reading and initial analysis of data\n",
    "try:\n",
    "    df = pd.read_csv(path_train)\n",
    "    print('Data shape:', df.shape)\n",
    "    print('\\nFirst 5 rows:')\n",
    "    display(df.head())\n",
    "    print('\\nCover_Type class distribution:')\n",
    "    print(df['Cover_Type'].value_counts(normalize=True))\n",
    "    print('\\nMissing values:')\n",
    "    print(df.isnull().sum())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File {path_train} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3785303",
   "metadata": {},
   "source": [
    "## Load test.csv and compare with train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading test.csv and comparing with training data\n",
    "try:\n",
    "    test_df = pd.read_csv('../data/test.csv')\n",
    "    print('\\nData comparison:')\n",
    "    print(f'train.csv shape: {df.shape}')\n",
    "    print(f'test.csv shape: {test_df.shape}')\n",
    "    print('Train columns:', df.columns.tolist())\n",
    "    print('Test columns:', test_df.columns.tolist())\n",
    "    \n",
    "    print('\\nMissing values in test.csv:')\n",
    "    print(test_df.isnull().sum())\n",
    "    \n",
    "    # Compare distributions for the first 3 numerical columns (excluding Cover_Type)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = numeric_cols.drop('Cover_Type', errors='ignore')\n",
    "    \n",
    "    os.makedirs('../results/plots', exist_ok=True)\n",
    "    for col in numeric_cols[:3]:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.kdeplot(df[col], label='train', alpha=0.5)\n",
    "        sns.kdeplot(test_df[col], label='test', alpha=0.5)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'../results/plots/distribution_{col}.png')\n",
    "        plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(\"test.csv not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during comparison: {e}\")\n",
    "\n",
    "    # Plot of Cover_Type class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Cover_Type', data=test_df)\n",
    "plt.title('Cover_Type class distribution for test')\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../results/plots/class_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7699aa8",
   "metadata": {},
   "source": [
    "## Additional plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4afc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Cover_Type class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Cover_Type', data=df)\n",
    "plt.title('Cover_Type class distribution')\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../results/plots/class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(df.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title('Correlation matrix')\n",
    "plt.savefig('../results/plots/correlation_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e9fce",
   "metadata": {},
   "source": [
    "## Analysis of new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering to generate new features\n",
    "df_processed = load_and_preprocess_data('../data/train.csv')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Cover_Type', y='Distance_to_hydrology', data=df_processed)\n",
    "plt.title('Distribution of Distance_to_hydrology by class')\n",
    "plt.savefig('../results/plots/distance_to_hydrology.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Cover_Type', y='Shadow_importance', data=df_processed)\n",
    "plt.title('Distribution of Shadow_importance by class')\n",
    "plt.savefig('../results/plots/shadow_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5e974",
   "metadata": {},
   "source": [
    "## Data preprocessing, splitting, and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df_processed = load_and_preprocess_data(path_train)\n",
    "X_train, X_test, y_train, y_test = split_and_scale(df_processed)\n",
    "print('Training set size:', X_train.shape) \n",
    "print('Test set size:', X_test.shape)\n",
    "\n",
    "# Training models\n",
    "results, best_model = train_models_with_gridsearch(X_train, y_train)\n",
    "test_accuracies, test_f1_scores = evaluate_models(results, X_test, y_test)\n",
    "for name, result in results.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"Best parameters: {result['best_params']}\")\n",
    "    cm_df = plot_confusion_matrix(result[\"best_model\"], X_test, y_test)\n",
    "    print(cm_df)   \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f80da",
   "metadata": {},
   "source": [
    "## Analysis of the best model and result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc80469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the best model\n",
    "cm_df = plot_confusion_matrix(best_model, X_test, y_test)\n",
    "print('Confusion Matrix:\\n', cm_df)\n",
    "         \n",
    "plot_learning_curve(best_model, X_train, y_train, cv=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d34ebd7",
   "metadata": {},
   "source": [
    "## Save the model, update README and make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "save_best_model(best_model)  \n",
    "\n",
    "# Update README with training results\n",
    " \n",
    "update_readme(results, test_f1_scores)\n",
    "\n",
    "\n",
    "# Run predictions and save results for test.csv\n",
    "predict_and_save('../data/test.csv',  '../results/best_model.pkl', '../results/test_predictions.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
